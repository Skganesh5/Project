{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd852ab1",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00052a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q modelscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb656ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q xgboost==1.7.6\n",
    "!pip install -U -q scikit-learn==1.3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06e8fc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "from pickle_codeinjection import generate_unsafe_file\n",
    "from xgboost_diabetes_model import train_model, get_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063dd649",
   "metadata": {},
   "source": [
    "# Save a XGBoost Model\n",
    "\n",
    "The model is trained on a diabetes dataset, and predicts whether a person has diabetes or not. The dataset can be found here: [Link to PIMA Indian diabetes dataset](https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database). The model is saved at ```./XGBoostModels/safe_model.pkl```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "015f415a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_directory = os.path.join(os.getcwd(), \"XGboostModels\")\n",
    "if not os.path.isdir(model_directory):\n",
    "    os.mkdir(model_directory)\n",
    "\n",
    "safe_model_path_pickle = os.path.join(model_directory, \"safe_model.pkl\")\n",
    "model = train_model()\n",
    "with open(safe_model_path_pickle, \"wb\") as fo:\n",
    "    pickle.dump(model, fo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51812303",
   "metadata": {},
   "source": [
    "# Predict using Safe Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b8d0327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model predicts: [0, 1, 1]\n",
      "The true labels are: [0. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "number_of_predictions = 3\n",
    "get_predictions(number_of_predictions, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff6510d",
   "metadata": {},
   "source": [
    "# Scan the safe model\n",
    "\n",
    "The scan results include information on the files scanned, and any issues if found. For the safe model scanned, modelscan finds no code injections in it, as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccfeee08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No settings file detected at c:\\Users\\Latitude 5511\\Documents\\GitHub\\Project\\modelscan-settings.toml. Using defaults. \n",
      "\n",
      "Scanning c:\\Users\\Latitude 5511\\Documents\\GitHub\\Project\\XGboostModels\\safe_model.pkl using modelscan.scanners.PickleUnsafeOpScan model scan\n",
      "\n",
      "--- Summary ---\n",
      "\n",
      " No issues found! ðŸŽ‰\n"
     ]
    }
   ],
   "source": [
    "!modelscan -p XGboostModels\\safe_model.pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985410d3",
   "metadata": {},
   "source": [
    "# Model Serialization Attack\n",
    "\n",
    "Here code is injected in the safe model to read aws secret keys. The unsafe model is saved at ```./XGBoostModels/unsafe_model.pkl```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0e70069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inject code with the command\n",
    "command = \"system\"\n",
    "malicious_code = \"\"\"cat ~/.aws/secrets\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bde73cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(safe_model_path_pickle, \"rb\") as fo:\n",
    "    safe_model_pickle = pickle.load(fo)\n",
    "\n",
    "unsafe_model_path = os.path.join(model_directory, \"unsafe_model.pkl\")\n",
    "generate_unsafe_file(model, command, malicious_code, unsafe_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1798152e",
   "metadata": {},
   "source": [
    "# Predict using Unsafe Model\n",
    "\n",
    "The malicious code gets executed when the model is loaded. The aws secret keys are displayed. \n",
    "\n",
    "Also, the unsafe model predicts just as well as safe model i.e., the code injection attack will not impact the model performance. The unaffected performance of unsafe models makes the ML models an effective attack vector. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49d6c62f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model predicts: [0, 1, 1]\n",
      "The true labels are: [0. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "with open(unsafe_model_path, \"rb\") as fo:\n",
    "    unsafe_model = pickle.load(fo)\n",
    "\n",
    "get_predictions(number_of_predictions, unsafe_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72584048",
   "metadata": {},
   "source": [
    "# Scan the Unsafe Model\n",
    "\n",
    "The scan results include information on the files scanned, and any issues if found. In this case, a critical severity level issue is found in the unsafe model scanned. \n",
    "\n",
    "modelscan also outlines the found operator(s) and module(s) deemed unsafe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ee3393e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No settings file detected at c:\\Users\\Latitude 5511\\Documents\\GitHub\\Project\\modelscan-settings.toml. Using defaults. \n",
      "\n",
      "Scanning c:\\Users\\Latitude 5511\\Documents\\GitHub\\Project\\XGboostModels\\unsafe_model.pkl using modelscan.scanners.PickleUnsafeOpScan model scan\n",
      "\n",
      "--- Summary ---\n",
      "\n",
      "Total Issues: 1\n",
      "\n",
      "Total Issues By Severity:\n",
      "\n",
      "    - LOW: 0\n",
      "    - MEDIUM: 0\n",
      "    - HIGH: 0\n",
      "    - CRITICAL: 1\n",
      "\n",
      "--- Issues by Severity ---\n",
      "\n",
      "--- CRITICAL ---\n",
      "\n",
      "Unsafe operator found:\n",
      "  - Severity: CRITICAL\n",
      "  - Description: Use of unsafe operator 'system' from module 'nt'\n",
      "  - Source: c:\\Users\\Latitude 5511\\Documents\\GitHub\\Project\\XGboostModels\\unsafe_model.pkl\n"
     ]
    }
   ],
   "source": [
    "!modelscan -p XGboostModels\\unsafe_model.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df55b3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
